{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão dos preços da habitação em Boston\n",
    "\n",
    "Neste estudo, daremos uma olhada no conjunto de dados Boston Housing Prices no Kaggle. Esse conjunto de dados é proveniente do UCI Machine Learning Repository e contém 506 linhas e 14 colunas. Cada linha representa uma casa localizada em Boston, Massachusetts em 1978 e as 14 colunas representam pontos de dados coletados em cada casa. O objetivo deste estudo é usar os dados coletados sobre cada residência para prever o valor médio da residência. Esta é uma tarefa de regressão supervisionada, que significa:\n",
    "\n",
    "- Supervisionado - A variável de destino está incluída no conjunto de dados.\n",
    "- Regressão - A variável de destino é contínua.\n",
    "\n",
    "Visão geral das features de conjunto de dados. Esta lista inclui uma descrição de todas as colunas no conjunto de dados.\n",
    "\n",
    "- CRIM - taxa de criminalidade per capita por cidade\n",
    "- ZN - proporção de terrenos residenciais divididos por lotes acima de 25.000 pés quadrados\n",
    "- INDUS - proporção de acres comerciais em áreas não comerciais por cidade\n",
    "- CHAS - variável fictícia Charles River (= 1 se o trecho limita o rio; 0 caso contrário)\n",
    "- NOX - concentração de óxidos nítricos (partes por 10 milhões)\n",
    "- RM - número médio de quartos por habitação\n",
    "- AGE - proporção de unidades ocupadas pelos proprietários construídas antes de 1940\n",
    "- DIS - distâncias ponderadas a cinco centros de emprego em Boston\n",
    "- RAD - índice de acessibilidade às rodovias radiais\n",
    "- TAX - taxa de imposto sobre a propriedade de valor total por USD 10,000 \n",
    "- PTRATIO - Relação aluno-professor por cidade\n",
    "- B - 1000 (Bk - 0,63) ^ 2 onde Bk é a proporção de negros por cidade\n",
    "- LSTAT - porcentagem de Status de classe inferior da população\n",
    "- MEDV (TARGET) - Valor médio das casas ocupadas pelos proprietários nos anos em USD 1,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "# Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo e verificando os dados\n",
    "\n",
    "column_headers = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', \\\n",
    "                  'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "%time boston = pd.read_csv(\"http://www.dropbox.com/s/hfyfc4mj7svavsb/housingdata.csv?dl=1\",  names = column_headers)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de dados possui 506 linhas (observações) e 14 colunas (features), incluindo nossa variável de destino MEDV. Uma coisa a ser observada logo de cara é que a coluna CHAS é uma variável binária e a variável RAD também parece ser uma variável categórica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira Regressão: BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = 'MEDV~CRIM+ZN+INDUS+CHAS+NOX+RM+AGE+DIS+RAD+TAX+PTRATIO+B+LSTAT'\n",
    "model = smf.ols(formula=function, data=boston).fit() \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE: Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(boston.MEDV, model.predict(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE: Root Mean Squared Error\n",
    "rmse = np.sqrt(mean_squared_error(boston.MEDV, model.predict(boston)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE: Mean Absolute Percentage Error\n",
    "mape = 100*np.mean(np.abs((boston.MEDV - model.predict(boston))/boston.MEDV))\n",
    "print('mape=',mape,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "# Análise Exploratória de Dados (EDA)\n",
    "\n",
    "EDA é o processo de entender o que os dados estão nos dizendo, calculando estatísticas e criando gráficos e figuras. Essas estatísticas e gráficos podem ajudar a encontrar anomalias que podem impactar nossa análise ou encontrar relacionamentos e tendências entre os vários recursos de nossos dados. A EDA começa em um nível alto, mas reduz seu escopo à medida que encontramos padrões e relacionamentos interessantes em nossos dados.\n",
    "\n",
    "## Estatísticas de distribuição e resumo da coluna MEDV (Destino)\n",
    "\n",
    "Este notebook está focado na criação de um modelo que use os 13 features em nosso conjunto de dados para prever a coluna MEDV, que é o valor médio da residência de cada residência no conjunto de dados (em milhares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['MEDV'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(boston['MEDV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a distribuição da coluna de destino está ligeiramente inclinada para a direita, com média de 22,53 e um desvio padrão de 9,20. Parece haver alguns valores discrepantes na extremidade superior da distribuição de preços MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores Faltantes\n",
    "\n",
    "Em seguida, precisamos verificar se o conjunto de dados tem algum valor ausente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install missingno --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno \n",
    "msno.matrix(boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é um conjunto de dados limpo, sem valores ausentes. Na maioria dos conjuntos de dados, esse não é o caso e é muito importante verificar se há valores ausentes, pois eles precisarão ser delt através da eliminação de colunas ou valores imputados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de coluna\n",
    "\n",
    "É importante entender os tipos de coluna porque um modelo de aprendizado de máquina não pode usar variáveis categóricas. As variáveis categóricas precisam ser codificadas como números antes de serem usadas pelo modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os tipos de coluna são int64 ou float64, o que indica que são todas colunas numéricas. Sabemos que o recurso CHAS é binário, portanto, ele pode aceitar apenas valores de 0 e 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalias e Outliers\n",
    "\n",
    "Uma maneira de verificar anomalias e discrepâncias nos dados é examinar as distribuições das features em nosso conjunto de dados, bem como as estatísticas resumidas de cada coluna. Para fazer isso, vou traçar alguns histogramas e usar o método .describe ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows = 7, ncols = 2, figsize=(16,16))\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
    "       'PTRATIO', 'B', 'LSTAT']\n",
    "row = 0\n",
    "col = 0\n",
    "for i, column in enumerate(columns):\n",
    "    g = sns.distplot(boston[column], ax=ax[row][col],kde_kws={'bw':1.5})\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        col = 0\n",
    "        row += 1\n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.iloc[:,:-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando para esses histogramas e estatísticas resumidas, notei algumas coisas interessantes:\n",
    "\n",
    "\n",
    "- A coluna TAX (taxa de imposto sobre a propriedade de valor total por USD 10,000) possui a maioria de seus valores na faixa de 200 a 400, mas há uma parte das casas com um valor de TAX acima de 600\n",
    "\n",
    "\n",
    "- A coluna RAD (Índice de acessibilidade às rodovias radiais) tem a maioria de seus valores entre 0 e 10, mas há uma parte dos valores acima de 20.\n",
    "\n",
    "\n",
    "- Muitas das colunas tem assimetria para a esquerda ou direita. Por exemplo, a coluna ZN (proporção de terrenos residenciais divididos por lotes acima de 25.000 pés quadrados) está fortemente inclinada para a direita. Gostaria de entender essa coluna com mais detalhes e seu efeito na coluna MEDV. O código abaixo irá explorar cada observação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a variável TAX\n",
    "\n",
    "Taxa de imposto sobre a propriedade de valor total por USD 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(boston.TAX, bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a variável RAD\n",
    "\n",
    "Índice de acessibilidade às rodovias radiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.RAD.value_counts().sort_values().plot(kind='barh', figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='RAD', y='MEDV', data=boston,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a variável ZN\n",
    "\n",
    "proporção de terrenos residenciais divididos por lotes acima de 25.000 pés quadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.ZN.value_counts().sort_values().plot(kind='barh', figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='ZN', y='MEDV', data=boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "372 observações são 0 para a coluna ZN, o que significa que esses lotes não excedem 25000 pés quadrados. As demais observações são distribuídas dos números 12.5-100, indicando a porcentagem de terras divididas para esse lote. Vamos tentar visualizar o efeito desses números na estatística MEDV.\n",
    "\n",
    "Para visualizá-lo, vou cortar a categoria ZN em 4 posições (0-24, 25-50, 51-75, 76, -100) e mapear o valor médio de MEDV para cada agrupamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(boston['ZN'], bins = 4).value_counts().sort_values().plot(kind='barh', figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_zn = boston.groupby(pd.cut(boston['ZN'], bins = 4)).mean()['MEDV']\n",
    "grouped_zn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(grouped_zn.index.astype(str), grouped_zn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe uma clara tendência positiva entre o zoneamento da terra e o valor residencial da MEDV. Intuitivamente, esse gráfico faz sentido, porque quanto menor o tamanho da terra, menor será o valor da casa. I.E. casas com mais terra tendem a valer mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlações\n",
    "\n",
    "Uma maneira de tentar entender os dados é procurar correlações entre os recursos e o destino. Podemos calcular o coeficiente de correlação de Pearson entre todas as variáveis e o alvo usando o método .corr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.corr()['MEDV'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em algumas das correlações mais significativas.\n",
    "\n",
    "- A correlação mais negativa é o LSTAT (porcentagem de Status de classe inferior da população); portanto, o que isso significa é que, enquanto mais a porcentagem  do status inferior da população aumenta para uma casa, o valor MEDV da casa tende a diminuir.\n",
    "\n",
    "- A correlação mais positiva (exceto MEDV) é RM (número médio de quartos por casa). Isso significa que, à medida que o número médio de quartos aumenta, o valor MEDV da casa tende a aumentar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de correlação\n",
    "\n",
    "Um ótimo acompanhamento para o parplot é a matriz de correlação. A matriz de correlação exibe as correlações para cada par de variáveis no conjunto de dados e pode facilitar a localização de recursos correlatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heatmap\n",
    "corr = boston.corr()\n",
    "plt.figure(figsize = (20,8))\n",
    "sns.heatmap(corr, annot=True,annot_kws={\"size\": 15},\n",
    "        linewidth=1,\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que parece haver uma forte relação entre os seguintes recursos:\n",
    "\n",
    "- TAX e RAD (TAX: taxa de imposto sobre a propriedade de valor total por USD 10,000 e RAD: índice de acessibilidade às rodovias radiais)\n",
    "\n",
    "\n",
    "- DIS e AGE (DIS: distâncias ponderadas a cinco centros de emprego em Boston e IDADE e AGE: proporção de unidades ocupadas pelos proprietários construídas antes de 1940)\n",
    "\n",
    "\n",
    "- DIS e NOX (DIS: distâncias ponderadas a cinco centros de emprego em Boston e NOX: concentração de óxidos nítricos (partes por 10 milhões))\n",
    "\n",
    "\n",
    "- DIS e INDUS (DIS: distâncias ponderadas a cinco centros de emprego em Boston e INDUS: proporção de acres comerciais em áreas não comerciais por cidade)\n",
    "\n",
    "\n",
    "- TAX e INDUS (TAX: taxa de imposto sobre a propriedade de valor total por USD 10,000 e INDUS: proporção de acres comerciais em áreas não comerciais por cidade)\n",
    "\n",
    "\n",
    "- NOX e INDUS (NOX: concentração de óxidos nítricos (partes por 10 milhões) e TAX: taxa de imposto sobre a propriedade de valor total por USD 10,000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot\n",
    "\n",
    "O parplot é uma ótima maneira de ver relacionamentos entre pares de variáveis. Podemos identificar variáveis colineares, bem como outras relações interessantes entre os preditores e a resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicolinearidade\n",
    "\n",
    "Nem todos os problemas de correlação podem ser detectados observando a matriz de pares ou parcelas de correlação. É possível que exista correlação entre três ou mais variáveis, denominadas multicolinearidade. Uma maneira de identificar a colinearidade e a multicolinearidade nos dados é calculando o fator de inflação de variância ou [Variance Inflator Factor](https://en.wikipedia.org/wiki/Variance_inflation_factor) para cada variável. um VIF 10 significa que a variável pode ser problemática e impactar os resultados de um modelo de regressão.\n",
    "\n",
    "Na estatística, o fator de inflação de variação (VIF) é o quociente da variação em um modelo com vários termos pela variação de um modelo com apenas um termo. Quantifica a severidade da multicolinearidade em uma análise de regressão de mínimos quadrados ordinária. Ele fornece um índice que mede o quanto a variação (o quadrado do desvio padrão da estimativa) de um coeficiente de regressão estimado é aumentada devido à colinearidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather features\n",
    "features = \"+\".join(boston.columns[:-1])\n",
    "\n",
    "# get y and X dataframes based on this regression:\n",
    "y, X = dmatrices('MEDV ~' + features, boston, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif.sort_values(by='VIF Factor', ascending=False).iloc[1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os fatores VIF para os recursos TAX e RAD são os mais altos dentre os recursos. Além disso, esses dois recursos estão altamente correlacionados entre si, conforme observado acima. Vamos tentar adicionar esses dois recursos juntos e ver se o fator VIF do novo recurso é menor que os dois anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_rad = boston.copy()\n",
    "tax_rad['taxrad'] = tax_rad['TAX'] + tax_rad['RAD']\n",
    "tax_rad = tax_rad.drop(['TAX', 'RAD'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather features\n",
    "features = \"+\".join(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'taxrad',\n",
    "       'PTRATIO', 'B', 'LSTAT'])\n",
    "\n",
    "# get y and X dataframes based on this regression:\n",
    "y, X = dmatrices('MEDV ~' + features, tax_rad, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif.sort_values(by='VIF Factor', ascending=False).iloc[1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos ver que o fator VIF do novo recurso \"taxrad\" possui um fator VIF significativamente menor do que os recursos TAX e RAD. Vamos manter isso em mente no futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_rad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear: Avaliando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = 'MEDV~CRIM+ZN+INDUS+CHAS+NOX+RM+AGE+DIS+taxrad+PTRATIO+B+LSTAT'\n",
    "model = smf.ols(formula=function, data=tax_rad).fit() \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE: Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(tax_rad.MEDV, model.predict(tax_rad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE: Root Mean Squared Error\n",
    "rmse = np.sqrt(mean_squared_error(tax_rad.MEDV, model.predict(tax_rad)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tax_rad.MEDV\n",
    "y_pred = model.predict(tax_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE: Mean Absolute Percentage Error\n",
    "mape = 100*np.mean(np.abs((y - y_pred)/y))\n",
    "print('mape=',mape,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "O Feature Engineering é o processo de construção de novos features a partir de features já existentes no conjunto de dados. Existem muitas maneiras de executar a feature engineering e uma maneira é através da construção de termos de interação entre os recursos. Isso inclui recursos atuais elevados a uma potência, recursos atuais multiplicados um pelo outro, etc. Eles são chamados de termos de interação porque capturam interações dentro de variáveis.\n",
    "\n",
    "## [sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "Gera features polinomiais e de interação.\n",
    "\n",
    "Gera uma nova matriz de features que consiste em todas as combinações polinomiais dos recursos com grau menor ou igual ao grau especificado. Por exemplo, se uma amostra de entrada é bidimensional e da forma $[a, b]$, os recursos polinomiais de grau 2 são $[1, a, b, a ^ 2, ab, b ^ 2]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe to capture polynomial features\n",
    "poly_features = boston.copy()\n",
    "\n",
    "#Capture target variable\n",
    "poly_target = poly_features['MEDV']\n",
    "poly_features = poly_features.drop(columns=['MEDV'])\n",
    "\n",
    "#Import polynomial feature module\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Create polynomial object with degree of 2\n",
    "poly_transformer = PolynomialFeatures(degree = 2)\n",
    "\n",
    "#Train the polynomial features\n",
    "poly_transformer.fit(poly_features)\n",
    "\n",
    "#Transform the features\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "\n",
    "print('Polynomial Features Shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(boston.columns[:-1]))\n",
    "\n",
    "#Add target back in to poly_features\n",
    "poly_features['MEDV'] = poly_target\n",
    "\n",
    "#Find correlations within target\n",
    "poly_corrs = poly_features.corr()['MEDV'].sort_values()\n",
    "\n",
    "print(poly_corrs.head(10))\n",
    "print(poly_corrs.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear: Melhorando as métricas de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = poly_features.drop(['MEDV'], axis=1)\n",
    "y = poly_features.MEDV\n",
    "\n",
    "lm = LinearRegression() # instanciar o modelo\n",
    "lm.fit(X, y)  # ajuste do modelo\n",
    "y_pred = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_Squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE: Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE: Root Mean Squared Error\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE: Mean Absolute Percentage Error\n",
    "mape = 100*np.mean(np.abs((y - y_pred)/y_pred))\n",
    "print('mape=',mape,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "## AVANÇADO: Regularização\n",
    "\n",
    "### Regressão de Ridge\n",
    "\n",
    "A regressão de Ridge é uma forma de regressão linear que introduziu regularização na forma da norma L2. Essa regularização visa reduzir os coeficientes do modelo de regressão linear, reduzindo, portanto, a chance de sobreajuste. Existem outros tipos de métodos de regressão de regularização, como laço e rede elástica. O Lasso é mais adequado para conjuntos de dados que contêm mais recursos, pois visa reduzir coeficientes insignificantes, reduzindo assim a dimensionalidade do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para ajuste, treino e teste do modelo de regressão linear\n",
    "def RidgeLR(data):\n",
    "    #dados de entrada\n",
    "    X = data.drop(columns='MEDV')\n",
    "    \n",
    "    #dados de saida\n",
    "    y = data['MEDV']\n",
    "    \n",
    "    #splitando os dados\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "    \n",
    "    #alphas = serie de parametros de distancia de Ridge\n",
    "    alphas = {'alpha':[.001, .01, .1, 10, 100]}\n",
    "    \n",
    "    #instanciando o modelo\n",
    "    ridge = Ridge(random_state = 101)\n",
    "    \n",
    "    #criando o grid search\n",
    "    clf = GridSearchCV(estimator=ridge, param_grid=alphas, cv=5, iid=True)\n",
    "    \n",
    "    #ajustando o modelo aos dados de treino\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #Make predictions using lm.predict\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    #imprimindo os resultados\n",
    "    print('r^2: ', r2_score(y_test, predictions))\n",
    "    print(\"MSE: \", mean_squared_error(y_test, predictions))\n",
    "    \n",
    "    return r2_score(y_test, predictions), mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridger2, bridgemse = RidgeLR(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyridger2, polyridgemse = RidgeLR(poly_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparando os resultados regularizados com os resultados anteriores\n",
    "RidgeLR = pd.DataFrame(data=[[bridger2, polyridger2], [bridgemse, polyridgemse]], columns=['ridge', 'poly features'], index=['r^2', 'MSE'])\n",
    "RidgeLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
